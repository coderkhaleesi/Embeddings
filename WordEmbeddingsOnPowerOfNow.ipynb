{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbeddingsOnPowerOfNow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyadixit21/Embeddings/blob/master/WordEmbeddingsOnPowerOfNow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JHqahUHgPBc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phraser, Phrases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KywoNK50MEO4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_path = 'PON.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CtLUaQvZMWaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(file_path, 'rb') as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oB1jVXMHMqtc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuWc-ZGMQHx9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_string = text.decode('utf-8',  errors='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKeeo3QsOGTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_clean1 = re.sub(r'\\r\\n', \" \", text_string)\n",
        "text_clean2 =  re.sub(r'n\\'t', \"not\", text_clean1)\n",
        "text_clean3 =  re.sub(r'-', \" \", text_clean2)\n",
        "text_clean4 =  re.sub(r'\\'s', \"is\", text_clean3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XawYYBgeQY1X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkM6wE4vQmgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = text_clean4.split(\".\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xK-xqJ6Qsym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_data = [sentence.split(\" \") for sentence in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rG6U963KRMx9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Word2Vec(input_data, \n",
        "                 min_count=3,   # Ignore words that appear less than this\n",
        "                 size=200,      # Dimensionality of word embeddings\n",
        "                 workers=2,     # Number of processors (parallelisation)\n",
        "                 window=5,      # Context window for words during training\n",
        "                 iter=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3apWts-KUof6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b633dbd9-5562-48aa-f451-3a5140bead35"
      },
      "cell_type": "code",
      "source": [
        "model.vector_size"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "0DdTqYKVYLDk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SYk-aV2CVuCZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.pydoc.io/pypi/gensim-3.2.0/autoapi/models/word2vec/index.html\n"
      ]
    },
    {
      "metadata": {
        "id": "8dNi-V04U4NP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "c448f981-4d98-4601-a040-3cc6a993833f"
      },
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=[\"meditation\"])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('automatic', 0.9691257476806641),\n",
              " ('cosmic', 0.9626511335372925),\n",
              " ('continuing', 0.9592429995536804),\n",
              " ('wonderful', 0.9587390422821045),\n",
              " ('ten', 0.9555143713951111),\n",
              " ('all,', 0.9551092386245728),\n",
              " ('existence,', 0.9545372724533081),\n",
              " ('repetitive', 0.9542608261108398),\n",
              " ('relief', 0.9534682035446167),\n",
              " ('today', 0.95293128490448)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "nvjMbkQ6Y3EN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Resources: https://www.shanelynn.ie/word-embeddings-in-python-with-spacy-and-gensim/\n",
        "\n",
        "https://github.com/facebookresearch/fastText\n",
        "\n",
        "Regexp: https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial\n",
        "\n",
        "https://towardsdatascience.com/deep-transfer-learning-for-natural-language-processing-text-classification-with-universal-1a2c69e5baa9\n",
        "\n",
        "https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\n",
        "\n",
        "https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a\n",
        "\n",
        "https://radimrehurek.com/gensim/models/fasttext.html#module-gensim.models.fasttext\n",
        "\n",
        "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb\n",
        "\n",
        "https://realpython.com/python-keras-text-classification/"
      ]
    },
    {
      "metadata": {
        "id": "c8NfY3jiWIxJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For better embeddings, we can use https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb\n"
      ]
    },
    {
      "metadata": {
        "id": "fJ6HLVrqZbbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Other resources:\n",
        "\n",
        "https://www.depends-on-the-definition.com/guide-to-word-vectors-with-gensim-and-keras/\n",
        "\n",
        "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
        "\n",
        "https://arxiv.org/pdf/1810.12406.pdf\n",
        "\n",
        "https://arxiv.org/pdf/1609.04309.pdf\n",
        "\n",
        "Faster Softmax:\n",
        "https://towardsdatascience.com/speed-up-your-deep-learning-language-model-up-to-1000-with-the-adaptive-softmax-part-1-e7cc1f89fcc9\n",
        "\n",
        "https://towardsdatascience.com/speed-up-your-deep-learning-language-model-up-to-1000-with-the-adaptive-softmax-part-2-pytorch-d47fe9a56152\n",
        "\n",
        "http://cs231n.stanford.edu/reports/2017/pdfs/130.pdf\n",
        "\n",
        "Visualization help: https://ahmedbesbes.com/sentiment-analysis-on-twitter-using-word2vec-and-keras.html\n",
        "\n",
        "https://www.reddit.com/r/MachineLearning/comments/338sqx/hierarchical_softmax_why_is_it_faster/\n",
        "https://adventuresinmachinelearning.com/word2vec-keras-tutorial/\n"
      ]
    }
  ]
}